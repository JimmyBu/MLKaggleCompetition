# -*- coding: utf-8 -*-
"""A4_Q8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r4U-JfvRGBEeKHwu1H-MevBmH6L9Lday

###8.1

###Import Packages
"""

import numpy as np
import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, f1_score
from sklearn.utils import resample
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from torch.utils.data import DataLoader, TensorDataset
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import tensorflow as tf
import xgboost as xgb
from tensorflow.keras import Model
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Dense, Dropout, Input, Flatten, Reshape, Conv1D, MaxPooling1D, LSTM, Bidirectional, Concatenate, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import accuracy_score
from sklearn.decomposition import PCA

from google.colab import drive
drive.mount('/content/drive')
train_path = '/content/drive/My Drive/train.csv'
test_path = '/content/drive/My Drive/test.csv'

df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

"""###Explore Data"""

df_train.head(), df_test.head()

df_train.info(), df_test.info()

"""###Distribution"""

plt.figure(figsize=(12, 6))
sns.histplot(df_train.iloc[:, 0], kde=True)
sns.histplot(df_test.iloc[:, 0], kde=True)
plt.title('Distribution')
plt.show()

"""###Pre-processing"""

# Print some rows to understand the structure
print(df_train.head())
print(df_test.head())

# Preprocessing
scaler = StandardScaler()
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

X_train_np = X_train.values
y_train_np = y_train.values
X_test_np = X_test.values

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled, X_val_scaled, y_train_np, y_val_np = train_test_split(
    X_train_scaled, y_train_np, test_size=0.2, random_state=42
)

# One-hot encode the labels
num_classes = len(np.unique(y_train_np))
y_train_one_hot = to_categorical(y_train_np, num_classes=num_classes)
y_val_one_hot = to_categorical(y_val_np, num_classes=num_classes)

# Convert numpy arrays to TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled.reshape(-1, 1, X_train_scaled.shape[1]), y_train_one_hot)) # Reshape data to be 3 dimensional
val_dataset = tf.data.Dataset.from_tensor_slices((X_val_scaled.reshape(-1, 1, X_val_scaled.shape[1]), y_val_one_hot)) # Reshape data to be 3 dimensional


# Shuffle, batch, and prefetch the training dataset
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.AUTOTUNE)
val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)

LATENT_SIZE = 32
input_size = X_train_scaled.shape[1]

"""###AdaBoost"""

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0, drop_last=True)

X_train_np = X_train_tensor.numpy()
y_train_np = y_train_tensor.numpy()
X_val_np = X_val.numpy()
y_val_np = y_val.numpy()
X_test_np = X_test_tensor.numpy()

# AdaBoost with a decision tree as the base estimator
ada_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)
ada_model.fit(X_train_np, y_train_np)

# Evaluate AdaBoost model
y_val_preds = ada_model.predict(X_val_np)
y_test_preds = ada_model.predict(X_test_np)

# Compute metrics
accuracy = accuracy_score(y_val_np, y_val_preds)
class_report = classification_report(y_val_np, y_val_preds)
f1 = f1_score(y_val_np, y_val_preds, average='weighted')

# Compute confusion matrix
cm = confusion_matrix(y_val_np, y_val_preds)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=np.unique(y_train_np),
            yticklabels=np.unique(y_train_np))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Track performance over different numbers of estimators
import matplotlib.pyplot as plt

train_scores = []
val_scores = []

for n_estimators in range(1, 101):
    ada_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                                   n_estimators=n_estimators, random_state=42)
    ada_model.fit(X_train_np, y_train_np)
    train_scores.append(ada_model.score(X_train_np, y_train_np))
    val_scores.append(ada_model.score(X_val_np, y_val_np))

plt.figure(figsize=(10, 6))
plt.plot(range(1, 51), train_scores, label='Training Accuracy')
plt.plot(range(1, 51), val_scores, label='Validation Accuracy')
plt.xlabel('Number of Estimators')
plt.ylabel('Accuracy')
plt.title('Learning Curve for AdaBoost')
plt.legend()
plt.show()

test_predictions = ada_model.predict(X_test_np)

results_df = pd.DataFrame({
    'ID': df_test['ID'],  # Ensure df_test contains 'ID' column
    'Label': test_predictions  # AdaBoost predictions
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""### Bagging + GRU + lstm + multi-head + sparse"""

class SparseLayer(nn.Module):
    def __init__(self, in_features, out_features, sparsity=0.5):
        super(SparseLayer, self).__init__()
        self.sparsity = sparsity
        self.weights = nn.Parameter(torch.randn(out_features, in_features))
        self.bias = nn.Parameter(torch.randn(out_features))

    def forward(self, x):
        # Apply sparsity to weights
        mask = torch.rand_like(self.weights) > self.sparsity
        sparse_weights = self.weights * mask.float()
        return F.linear(x, sparse_weights, self.bias)

class SimpleNN(nn.Module):
    def __init__(self):
        super().__init__()
        input_size = X_train_tensor.shape[1]
        hidden_size = 32
        num_layers = 2

        # LSTM Layer
        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers,
                            bidirectional=True, dropout=0.5)
        # Multihead Attention Layer
        self.attention = nn.MultiheadAttention(embed_dim=hidden_size * 2, num_heads=4, batch_first=True)
        # GRU Layer
        self.gru = nn.GRU(input_size=input_size, hidden_size=32, batch_first=True, num_layers=2, dropout=0.5)
        # Dense Layer
        self.sparse_fc1 = SparseLayer(hidden_size * 2 + hidden_size, 128, sparsity=0.5)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, len(np.unique(y_train_tensor)))
        self.dropout = nn.Dropout(p=0.5)

    def forward(self, x):
        # LSTM
        lstm_out, _ = self.lstm(x)
        # print(f'LSTM output shape: {lstm_out.shape}')

        # Multihead Attention
        attention_out, _ = self.attention(lstm_out, lstm_out, lstm_out)
        # print(f'Attention output shape: {attention_out.shape}')

        # GRU
        gru_out, _ = self.gru(x)
        # print(f'GRU output shape: {gru_out.shape}')

        """
        if lstm_out.dim() == 3:
            lstm_last_out = lstm_out[:, -1, :]  # Extract last timestep for 3D tensor
        else:
        """

        lstm_last_out = lstm_out  # For 2D tensor, use as is or adjust based on context
        gru_last_out = gru_out

        # Concatenate the outputs
        combined_out = torch.cat((lstm_last_out, gru_last_out), dim=1)

        out = F.relu(self.sparse_fc1(combined_out))
        out = self.dropout(out)
        out = F.relu(self.fc2(out))
        out = self.dropout(out)
        out = self.fc3(out)
        return out

# Bagging
class BaggingClassifier:
    def __init__(self, model_class, n_estimators=5, **model_kwargs):
        self.model_class = model_class
        self.n_estimators = n_estimators
        self.model_kwargs = model_kwargs
        self.models = []
        self.train_losses_per_model = []

    def fit(self, X_train, y_train, num_epochs=100, batch_size=64, learning_rate=0.001):
        for _ in range(self.n_estimators):
            # Create a bootstrap sample
            X_resampled, y_resampled = resample(X_train, y_train)
            train_dataset = TensorDataset(torch.tensor(X_resampled, dtype=torch.float32),
                                          torch.tensor(y_resampled, dtype=torch.long))
            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)

            # Initialize and train the model
            model = self.model_class(**self.model_kwargs)
            train_losses = self._train_model(model, train_loader, num_epochs, learning_rate)
            self.models.append(model)
            self.train_losses_per_model.append(train_losses)

    def _train_model(self, model, train_loader, num_epochs, learning_rate):
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)

        train_losses = []

        for epoch in range(num_epochs):
            model.train()
            epoch_loss = 0

            for inputs, labels in train_loader:
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()

            train_losses.append(epoch_loss / len(train_loader))

        return train_losses

    def predict(self, X):
        all_preds = np.zeros((X.shape[0], len(np.unique(y_train_tensor))))
        for model in self.models:
            model.eval()
            with torch.no_grad():
                outputs = model(torch.tensor(X, dtype=torch.float32))
                preds = torch.argmax(outputs, dim=1).numpy()
                all_preds += np.eye(len(np.unique(y_train_tensor)))[preds]

        final_preds = np.argmax(all_preds, axis=1)
        return final_preds

# Training
# ----------------------------------------------------------------------------------------------------------------------
def train_and_evaluate(model, train_loader, val_loader, learning_rate=0.001, num_epochs=100):

    criterion = nn.CrossEntropyLoss()  # cross-entropy loss
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    train_losses, val_losses = [], []

    for epoch in range(num_epochs):
        model.train()
        epoch_train_loss = 0

        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)

            labels = labels.squeeze()
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()
            epoch_train_loss += loss.item()

        train_losses.append(epoch_train_loss / len(train_loader))

        model.eval()
        epoch_val_loss = 0
        all_labels, all_preds = [], []
        with torch.no_grad():
            for inputs, labels in val_loader:
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                epoch_val_loss += loss.item()

                _, preds = torch.max(outputs, 1)
                all_labels.extend(labels.cpu().numpy())
                all_preds.extend(preds.cpu().numpy())

        val_losses.append(epoch_val_loss / len(val_loader))
        accuracy = accuracy_score(all_labels, all_preds)
        class_report = classification_report(all_labels, all_preds)
        f1 = f1_score(all_labels, all_preds, average='weighted')

        # print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')

    return train_losses, val_losses, accuracy, class_report, f1

# Eval with Bagging
bagging_model = BaggingClassifier(model_class=SimpleNN, n_estimators=5)
bagging_model.fit(X_train_tensor.numpy(), y_train_tensor.numpy(), num_epochs=100, batch_size=64,
                  learning_rate=0.001)
y_val_preds = bagging_model.predict(X_val.numpy())
y_test_preds = bagging_model.predict(X_test_tensor.numpy())

# Compute metrics
accuracy = accuracy_score(y_val.numpy(), y_val_preds)
class_report = classification_report(y_val.numpy(), y_val_preds)
f1 = f1_score(y_val.numpy(), y_val_preds, average='weighted')

# Plots
# ----------------------------------------------------------------------------------------------------------------------
print(f'Validation Accuracy: {accuracy:.4f}')
print(f'Validation F1 Score: {f1:.4f}')
print(class_report)

# Save test predictions
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_preds
})
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

# Plot train vs validation loss
plt.figure(figsize=(12, 6))
for i, losses in enumerate(bagging_model.train_losses_per_model):
    plt.plot(losses, label=f'Model {i + 1} Train Loss')
plt.title('Model Loss')
plt.legend()
plt.tight_layout()
plt.show()

"""###Avg of AutoEncoder + XGBoost"""

encoder_input = Input(shape=(input_size,))
encoded = Dense(512, activation='relu')(encoder_input)
encoded = Dropout(0.7)(encoded)
encoded = Dense(256, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(128, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(64, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(LATENT_SIZE, activation='relu')(encoded)

encoder_model = Model(encoder_input, encoded)

# Decoder (Autoencoder)
decoder_input = Input(shape=(LATENT_SIZE,))
decoded = Dense(64, activation='relu')(decoder_input)
decoded = Dropout(0.9)(decoded)
decoded = Dense(128, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(256, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(512, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(input_size, activation='sigmoid')(decoded)

decoder_model = Model(decoder_input, decoded)

# Build the Autoencoder
autoencoder_input = Input(shape=(input_size,))
encoded_img = encoder_model(autoencoder_input)
decoded_img = decoder_model(encoded_img)
autoencoder_model = Model(autoencoder_input, decoded_img)

# Learning rate schedule and callbacks
lr_schedule = ExponentialDecay(initial_learning_rate=1e-3, decay_steps=10000, decay_rate=0.9)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)
optimizer = Adam(learning_rate=lr_schedule)

autoencoder_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
autoencoder_model.fit(X_train_scaled, X_train_scaled, epochs=100, validation_data=(X_val_scaled, X_val_scaled), callbacks=[early_stopping, reduce_lr])

# Feature Extraction
X_train_encoded = encoder_model.predict(X_train_scaled)
X_val_encoded = encoder_model.predict(X_val_scaled)
X_test_encoded = encoder_model.predict(X_test_scaled)

# Train XGBoost model
dtrain = xgb.DMatrix(X_train_encoded, label=y_train_np)
dval = xgb.DMatrix(X_val_encoded, label=y_val_np)

params = {
    'objective': 'multi:softmax',
    'num_class': num_classes,
    'eval_metric': 'mlogloss',
    'eta': 0.1,
    'max_depth': 6,
    'alpha': 10
}

xgb_model = xgb.train(params, dtrain, num_boost_round=100, evals=[(dval, 'eval')])
y_pred_xgb = xgb_model.predict(xgb.DMatrix(X_val_encoded))
accuracy_xgb = accuracy_score(y_val_np, y_pred_xgb)
print(f'XGBoost Accuracy: {accuracy_xgb * 100:.2f}%')

# Predictions from XGBoost
test_predictions_xgb = xgb_model.predict(xgb.DMatrix(X_test_encoded))
results_df_xgb = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': test_predictions_xgb.astype(int)
})
results_df_xgb.to_csv('submission_xgboost.csv', index=False)

# Define and train the final stacking model
stacked_features = np.concatenate([X_train_encoded, X_train_encoded], axis=1)  # Stacking the features
stacked_model = xgb.XGBClassifier(
    objective='multi:softmax',
    num_class=num_classes,
    eval_metric='mlogloss',
    eta=0.1,
    max_depth=6,
    alpha=10
)
stacked_model.fit(stacked_features, y_train_np)

# Make predictions with the stacking model
X_test_stacked_features = np.concatenate([X_test_encoded, X_test_encoded], axis=1)
test_predictions_stacked = stacked_model.predict(X_test_stacked_features)
results_df_stacked = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': test_predictions_stacked
})
results_df_stacked.to_csv('submission_stacked.csv', index=False)

"""###Autoencoder + CNN + RNN + GRU + LSTM + multihead"""

encoder_input = Input(shape=(input_size,))
encoded = Dense(512, activation='relu')(encoder_input)
encoded = Dropout(0.7)(encoded)
encoded = Dense(256, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(128, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(64, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(LATENT_SIZE, activation='relu')(encoded)

encoder_model = Model(encoder_input, encoded)

# Decoder (Autoencoder)
decoder_input = Input(shape=(LATENT_SIZE,))
decoded = Dense(64, activation='relu')(decoder_input)
decoded = Dropout(0.9)(decoded)
decoded = Dense(128, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(256, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(512, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(num_classes, activation='softmax')(decoded)

decoder_model = Model(decoder_input, decoded)

# Build the Autoencoder
autoencoder_input = Input(shape=(input_size,))
encoded_img = encoder_model(autoencoder_input)
decoded_img = decoder_model(encoded_img)
autoencoder_model = Model(autoencoder_input, decoded_img)

# Learning rate schedule
lr_schedule = ExponentialDecay(initial_learning_rate=1e-3, decay_steps=10000, decay_rate=0.9)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)
optimizer = Adam(learning_rate=lr_schedule)

autoencoder_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
autoencoder_model.summary()

# Train the Autoencoder
autoencoder_model.fit(train_dataset, epochs=100, validation_data=val_dataset, callbacks=[early_stopping, reduce_lr])

# Feature Extraction
X_train_encoded = encoder_model.predict(X_train_scaled)
X_val_encoded = encoder_model.predict(X_val_scaled)
X_test_encoded = encoder_model.predict(X_test_scaled)

# Define the Classification Model
classification_input = Input(shape=(LATENT_SIZE,))

# CNN Layer
cnn_out = Reshape((LATENT_SIZE, 1))(classification_input)
cnn_out = Conv1D(32, kernel_size=3, activation='relu', padding='same')(cnn_out)
cnn_out = BatchNormalization()(cnn_out)
cnn_out = MaxPooling1D(pool_size=2)(cnn_out)
cnn_out = Conv1D(64, kernel_size=3, activation='relu', padding='same')(cnn_out)
cnn_out = MaxPooling1D(pool_size=2)(cnn_out)
cnn_out = BatchNormalization()(cnn_out)
cnn_out = Flatten()(cnn_out)
cnn_out = Dropout(0.9)(cnn_out)

# LSTM, GRU, and RNN Layers
rnn_out = Reshape((LATENT_SIZE, 1))(classification_input)
rnn_out = Bidirectional(LSTM(64, return_sequences=True))(rnn_out)
rnn_out = Dropout(0.9)(rnn_out)
rnn_out = Bidirectional(GRU(64, return_sequences=True))(rnn_out)
rnn_out = Dropout(0.9)(rnn_out)
rnn_out = Bidirectional(SimpleRNN(64, return_sequences=True))(rnn_out)
rnn_out = Dropout(0.9)(rnn_out)

# MultiHeadAttention Mechanism
attention_input = Reshape((LATENT_SIZE, 1))(classification_input)
attention_out = MultiHeadAttention(num_heads=4, key_dim=64)(attention_input, attention_input)
attention_out = GlobalAveragePooling1D()(attention_out)
attention_out = Dropout(0.9)(attention_out)

# Combine outputs
rnn_out = Flatten()(rnn_out)
attention_out = tf.repeat(attention_out, repeats=512, axis=-1)
combined = Concatenate()([cnn_out, rnn_out, attention_out])

# Final Dense Layers
x = Dense(128, activation='relu')(combined)
x = Dropout(0.9)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.9)(x)
output = Dense(num_classes, activation='softmax')(x)

# Final Classification Model
classification_model = Model(classification_input, output)
classification_optimizer = Adam(learning_rate=lr_schedule)

classification_model.compile(optimizer=classification_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
classification_model.summary()

# Train the classification model
classification_model.fit(X_train_encoded, y_train_one_hot, epochs=100, validation_data=(X_val_encoded, y_val_one_hot), callbacks=[early_stopping, reduce_lr])

# Make predictions with the classification model
test_predictions = classification_model.predict(X_test_encoded)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': np.argmax(test_predictions, axis=1)
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###Bagging + Callbacks"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.base import BaseEstimator, ClassifierMixin
from tensorflow.keras.layers import Dense, Dropout, Input, Flatten, Reshape, Conv1D, MaxPooling1D, LSTM, SimpleRNN, GRU, MultiHeadAttention, GlobalAveragePooling1D, Bidirectional, Concatenate, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.utils import class_weight

# Define a wrapper class for the TensorFlow model to be used with scikit-learn
class KerasClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self, build_fn, **kwargs):
        self.build_fn = build_fn
        self.kwargs = kwargs
        self.model = None

    def build_model(self):
        self.model = self.build_fn()

    def fit(self, X, y):
        self.build_model()
        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        self.model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2, verbose=0)
        return self

    def predict(self, X):
        return np.argmax(self.model.predict(X), axis=1)


# Preprocessing
scaler = StandardScaler()
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

X_train_np = X_train.values
y_train_np = y_train.values
X_test_np = X_test.values

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled, X_val_scaled, y_train_np, y_val_np = train_test_split(
    X_train_scaled, y_train_np, test_size=0.2, random_state=42
)

# One-hot encode the labels
num_classes = len(np.unique(y_train_np))
y_train_one_hot = to_categorical(y_train_np, num_classes=num_classes)
y_val_one_hot = to_categorical(y_val_np, num_classes=num_classes)

# Convert numpy arrays to TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train_one_hot))
val_dataset = tf.data.Dataset.from_tensor_slices((X_val_scaled, y_val_one_hot))

# Shuffle, batch, and prefetch the training dataset
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.AUTOTUNE)
val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)

# Define and compile the Autoencoder model
LATENT_SIZE = 32
input_size = X_train_scaled.shape[1]

encoder_input = Input(shape=(input_size,))
encoded = Dense(512, activation='relu')(encoder_input)
encoded = Dropout(0.7)(encoded)
encoded = Dense(256, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(128, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(64, activation='relu')(encoded)
encoded = Dropout(0.7)(encoded)
encoded = Dense(LATENT_SIZE, activation='relu')(encoded)

encoder_model = Model(encoder_input, encoded)

# Decoder (Autoencoder)
decoder_input = Input(shape=(LATENT_SIZE,))
decoded = Dense(64, activation='relu')(decoder_input)
decoded = Dropout(0.9)(decoded)
decoded = Dense(128, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(256, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(512, activation='relu')(decoded)
decoded = Dropout(0.9)(decoded)
decoded = Dense(num_classes, activation='softmax')(decoded)

decoder_model = Model(decoder_input, decoded)

# Build the Autoencoder
autoencoder_input = Input(shape=(input_size,))
encoded_img = encoder_model(autoencoder_input)
decoded_img = decoder_model(encoded_img)
autoencoder_model = Model(autoencoder_input, decoded_img)

# Learning rate schedule
lr_schedule = ExponentialDecay(initial_learning_rate=1e-3, decay_steps=10000, decay_rate=0.9)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)
optimizer = Adam(learning_rate=lr_schedule)

autoencoder_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
autoencoder_model.summary()

# Train the Autoencoder
autoencoder_model.fit(train_dataset, epochs=100, validation_data=val_dataset, callbacks=[early_stopping, reduce_lr])

# Feature Extraction
X_train_encoded = encoder_model.predict(X_train_scaled)
X_val_encoded = encoder_model.predict(X_val_scaled)
X_test_encoded = encoder_model.predict(X_test_scaled)

# Create the Bagging Classifier using the Keras model
bagging_model = BaggingClassifier(
    estimator=KerasClassifier(build_fn=build_classification_model, epochs=10, batch_size=32),
    n_estimators=10,
    max_samples=0.8,
    max_features=0.8,
    n_jobs=-1
)

# Train the Bagging Classifier
bagging_model.fit(X_train_encoded, y_train_np)

# Make predictions with the Bagging Classifier
test_predictions = bagging_model.predict(X_test_encoded)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': test_predictions
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""#Bidirection LSTM + GRU + MultiHead + Bagging"""

def create_bidirectional_lstm_attention_model(num_classes, dropout_rate, num_heads, key_dim):
    inputs = Input(shape=(1, input_size))

    # Bidirectional LSTM layer
    x = Bidirectional(LSTM(64, return_sequences=True))(inputs)

    # MultiHead Attention layer
    attention = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)
    attention = LayerNormalization()(attention)

    # Combine attention output with LSTM output
    combined = tf.keras.layers.Concatenate()([x, attention])

    x = GlobalAveragePooling1D()(combined)
    x = Dense(64, activation='relu')(x)
    x = Dropout(dropout_rate)(x)
    outputs = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=inputs, outputs=outputs)
    return model

def create_gru_attention_model(num_classes, dropout_rate, num_heads, key_dim):
    inputs = Input(shape=(1, input_size))

    # Bidirectional GRU layer
    x = Bidirectional(GRU(64, return_sequences=True))(inputs)

    # MultiHead Attention layer
    attention = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)
    attention = LayerNormalization()(attention)

    # Combine attention output with GRU output
    combined = tf.keras.layers.Concatenate()([x, attention])

    x = GlobalAveragePooling1D()(combined)
    x = Dense(64, activation='relu')(x)
    x = Dropout(dropout_rate)(x)
    outputs = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=inputs, outputs=outputs)
    return model

num_models = 5
autoencoders = []
dropout_rates = [0.5, 0.6, 0.7, 0.8, 0.9]  # Different dropout rates
num_heads_list = [2, 4, 6, 8, 10]  # Different number of attention heads
key_dim_list = [32, 64, 128, 256, 512]  # Different key dimensions

for i in range(num_models):
    print(f"Training model {i+1}/{num_models}")

    # Select model type and hyperparameters
    dropout_rate = dropout_rates[i]
    num_heads = num_heads_list[i]
    key_dim = key_dim_list[i]

    # Choose model type (alternating between LSTM+Attention and GRU+Attention)
    if i % 2 == 0:
        model = create_bidirectional_lstm_attention_model(
            num_classes=num_classes,
            dropout_rate=dropout_rate,
            num_heads=num_heads,
            key_dim=key_dim
        )
    else:
        model = create_gru_attention_model(
            num_classes=num_classes,
            dropout_rate=dropout_rate,
            num_heads=num_heads,
            key_dim=key_dim
        )

    # Define callbacks
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)
    checkpoint = ModelCheckpoint(f'best_model_{i+1}.h5', save_best_only=True, monitor='val_loss')

    # Compile the model
    lr_schedule = ExponentialDecay(initial_learning_rate=1e-3, decay_steps=10000, decay_rate=0.9)
    model.compile(
        optimizer=Adam(learning_rate=lr_schedule),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # Train the model
    model.fit(
        train_dataset,
        epochs=100,
        validation_data=val_dataset,
        callbacks=[reduce_lr, checkpoint]
    )

    # Load the best weights
    model.load_weights(f'best_model_{i+1}.h5')

    # Append to list
    autoencoders.append(model)

print("Training completed for all models.")

def predict_with_autoencoders(autoencoders, data):
    num_classes = autoencoders[0].output_shape[-1]  # Get number of classes from the first model
    predictions = np.zeros((data.shape[0], num_classes))

    for autoencoder in autoencoders:
        model_predictions = autoencoder.predict(data)
        predictions += model_predictions

    # Average the predictions
    predictions /= len(autoencoders)
    return predictions

# Ensure the data has the correct shape
X_test_scaled = np.expand_dims(X_test_scaled, axis=1)  # Add time step dimension

# Make predictions on the test data
test_predictions = predict_with_autoencoders(autoencoders, X_test_scaled)

print("Test Predictions:")
print(test_predictions)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],  # Assuming 'ID' column exists in df_test
    'Label': np.argmax(test_predictions, axis=1)  # Get the index of the max value
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('Results saved to submission.csv')

"""Pure Tabular Autoencoder / Bagging + Autoencoder"""

def create_autoencoder(dropout_rate, num_heads, key_dim):
    # Encoder
    encoder_input = Input(shape=(input_size,))
    encoded = Dense(512, activation='relu')(encoder_input)
    encoded = Dropout(dropout_rate)(encoded)
    encoded = Dense(256, activation='relu')(encoded)
    encoded = Dropout(dropout_rate)(encoded)
    encoded = Dense(128, activation='relu')(encoded)
    encoded = Dropout(dropout_rate)(encoded)
    encoded = Dense(64, activation='relu')(encoded)
    encoded = Dropout(dropout_rate)(encoded)
    encoded = Dense(LATENT_SIZE, activation='relu')(encoded)

    # Reshape for attention
    reshaped_encoded = Reshape((LATENT_SIZE, 1))(encoded)
    encoded_with_attention = Bidirectional(LSTM(64, return_sequences=True))(reshaped_encoded)
    encoded_with_attention = Dropout(dropout_rate)(encoded_with_attention)

    # MultiHeadAttention layer
    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(encoded_with_attention, encoded_with_attention)
    attention_output = GlobalAveragePooling1D()(attention_output)

    # Decoder
    decoded = Dense(64, activation='relu')(attention_output)
    decoded = Dropout(dropout_rate)(decoded)
    decoded = Dense(128, activation='relu')(decoded)
    decoded = Dropout(dropout_rate)(decoded)
    decoded = Dense(256, activation='relu')(decoded)
    decoded = Dropout(dropout_rate)(decoded)
    decoded = Dense(512, activation='relu')(decoded)
    decoded = Dropout(dropout_rate)(decoded)
    decoded = Dense(num_classes, activation='sigmoid')(decoded)

    # Build the Autoencoder
    autoencoder_model = Model(encoder_input, decoded)

    return autoencoder_model

num_models = 5
autoencoders = []
dropout_rates = [0.5, 0.6, 0.7, 0.8, 0.9]  # Different dropout rates
num_heads_list = [2, 4, 6, 8, 10]  # Different number of attention heads
key_dim_list = [32, 64, 128, 256, 512]  # Different key dimensions

for i in range(num_models):
    print(f"Training autoencoder {i+1}/{num_models}")
    # Create a new autoencoder model with different hyperparameters
    dropout_rate = dropout_rates[i]
    num_heads = num_heads_list[i]
    key_dim = key_dim_list[i]
    autoencoder_model = create_autoencoder(dropout_rate=dropout_rate, num_heads=num_heads, key_dim=key_dim)

    # Define callbacks
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)
    checkpoint = ModelCheckpoint(f'best_model_{i+1}.h5', save_best_only=True, monitor='val_loss')

    # Compile the model
    lr_schedule = ExponentialDecay(initial_learning_rate=1e-3, decay_steps=10000, decay_rate=0.9)
    autoencoder_model.compile(
        optimizer=Adam(learning_rate=lr_schedule),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # Train the model
    autoencoder_model.fit(
        train_dataset,
        epochs=100,
        validation_data=val_dataset,
        callbacks=[reduce_lr, checkpoint]
    )

    # Load the best weights
    autoencoder_model.load_weights(f'best_model_{i+1}.h5')

    # Append to list
    autoencoders.append(autoencoder_model)

print("Training completed for all autoencoders.")

def predict_with_autoencoders(autoencoders, data):
    predictions = np.zeros((data.shape[0], num_classes))
    for autoencoder in autoencoders:
        predictions += autoencoder.predict(data)

    # Average the predictions
    predictions /= len(autoencoders)
    return predictions

# Make predictions on the test data
test_predictions = predict_with_autoencoders(autoencoders, X_test_scaled)

print(test_predictions)
# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': np.argmax(test_predictions, axis=1)
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###TabNet (trying PCA)"""

!pip install pytorch-tabnet

pca = PCA(n_components=0.9)  # Retain 90% of the variance
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Split the data
X_train_pca, X_val_pca, y_train_np, y_val_np = train_test_split(
    X_train_pca, y_train_np, test_size=0.2, random_state=42
)

from pytorch_tabnet.tab_model import TabNetClassifier

tabnet_model = TabNetClassifier(
    n_d=4,  # Number of decision steps
    n_a=4,  # Number of attention steps
    n_steps=2,  # Number of steps in the network
    gamma=1.3,  # Relaxation parameter
    n_independent=1,  # Number of independent layers
    n_shared=1,  # Number of shared layers
    seed=42
)

# Train the model
tabnet_model.fit(
    X_train=X_train_pca,
    y_train=y_train_np,
    eval_set=[(X_val_pca, y_val_np)],
    eval_name=['val'],
    eval_metric=['accuracy'],
    batch_size=128,
    virtual_batch_size=32,
    num_workers=0,
    drop_last=False
)

# Predict on validation set
y_val_pred = tabnet_model.predict(X_val_pca)
accuracy = accuracy_score(y_val_np, y_val_pred)
print(f'Validation Accuracy: {accuracy:.4f}')

# Predict on test set
y_test_pred = tabnet_model.predict(X_test_pca)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_pred
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###MetaTree"""

!pip install metatreelib

!pip install fsspec==2024.6.1

import sys
sys.path.append('..')

from metatree.model_metatree import LlamaForMetaTree as MetaTree
from metatree.decision_tree_class import DecisionTree, DecisionTreeForest
from metatree.run_train import preprocess_dimension_patch
from transformers import AutoConfig

from sklearn.metrics import accuracy_score
import sklearn

import torch
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import imodels
import random

model_name_or_path = "yzhuang/MetaTree"

config = AutoConfig.from_pretrained(model_name_or_path)
model = MetaTree.from_pretrained(
    model_name_or_path,
    config=config,
)
decision_tree_forest = DecisionTreeForest()

ensemble_size = 1
seed = 42

"""###CatBoost"""

import pandas as pd
import numpy as np
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

# Paths to data files
train_path = 'train.csv'
test_path = 'test.csv'

# Load data
df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

# Define features and labels
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Split the data into training and validation sets
X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(
    X_train_scaled, y_train, test_size=0.2, random_state=42
)

# Initialize the CatBoost model
model = CatBoostClassifier(
    iterations=1000,  # Number of boosting iterations
    depth=6,  # Depth of the trees
    learning_rate=0.1,  # Learning rate
    loss_function='MultiClass',  # Loss function for classification
    cat_features=[]  # List of categorical features if any (empty if no categorical features)
)

# Fit the model
model.fit(X_train_scaled, y_train)

# Make predictions on the validation set
y_val_pred = model.predict(X_val_scaled)
accuracy = accuracy_score(y_val, y_val_pred)
print(f'Validation Accuracy: {accuracy:.4f}')

# Make predictions on the test set
y_test_pred = model.predict(X_test_scaled)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_pred
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###Multinomial Naive Bayes"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report
from sklearn.preprocessing import KBinsDiscretizer

# Assuming X_train_scaled contains your standardized data
est = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')
X_train_discretized = est.fit_transform(X_train_scaled)

model = MultinomialNB()
model.fit(X_train_discretized, y_train_np)

# You should also discretize X_test before prediction
X_test_discretized = est.transform(X_test)
y_pred = model.predict(X_test_discretized)

results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_pred
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###SVM with RBF Kernel"""

from sklearn.svm import SVC
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

model = SVC(kernel='rbf', C=1, gamma='scale')
model.fit(X_train_scaled, y_train_np)

y_pred = model.predict(X_test_scaled)

results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_pred
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###Tabular AutoEncoder"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, f1_score
from sklearn.linear_model import LogisticRegression

train_path = 'train.csv'
test_path = 'test.csv'

df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

scaler = StandardScaler()
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Splitting data for training and validation
X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)

X_train, X_val, y_train, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.2, random_state=42)

# One-hot encoding
num_classes = len(torch.unique(y_train_tensor))
y_train_one_hot = F.one_hot(y_train, num_classes=num_classes).float()
y_val_one_hot = F.one_hot(y_val, num_classes=num_classes).float()

train_dataset = TensorDataset(X_train, y_train_one_hot)
val_dataset = TensorDataset(X_val, y_val_one_hot)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0, drop_last=True)


class Autoencoder(nn.Module):
    def __init__(self, D_in, H=50, H2=12, latent_dim=3, hidden_dim=64, num_layers=2):
        super(Autoencoder, self).__init__()
        # Encoder
        self.linear1 = nn.Linear(D_in, H)
        self.lin_bn1 = nn.BatchNorm1d(num_features=H)
        self.linear2 = nn.Linear(H, H2)
        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)
        self.linear3 = nn.Linear(H2, H2)
        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)
        self.fc1 = nn.Linear(H2, latent_dim)
        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)
        self.fc21 = nn.Linear(latent_dim, latent_dim)
        self.fc22 = nn.Linear(latent_dim, latent_dim)
        self.fc3 = nn.Linear(latent_dim, latent_dim)
        self.fc_bn3 = nn.BatchNorm1d(latent_dim)

        # GRU Layer
        self.gru = nn.GRU(input_size=latent_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True,
                          bidirectional=True, dropout=0.3)
        self.dropout = nn.Dropout(p=0.5)

        # Attention Layer
        self.attention = nn.MultiheadAttention(embed_dim=hidden_dim * 2, num_heads=2, batch_first=True)

        # Decoder
        self.fc4 = nn.Linear(hidden_dim * 2, H2)
        self.fc_bn4 = nn.BatchNorm1d(H2)
        self.linear4 = nn.Linear(H2, H2)
        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)
        self.linear5 = nn.Linear(H2, H)
        self.lin_bn5 = nn.BatchNorm1d(num_features=H)
        self.linear6 = nn.Linear(H, D_in)
        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)
        self.relu = nn.ReLU()
        self.softmax = nn.Softmax(dim=1)  # Add Softmax layer

    def encode(self, x):
        lin1 = self.relu(self.lin_bn1(self.linear1(x)))
        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))
        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))
        fc1 = F.relu(self.bn1(self.fc1(lin3)))
        r1 = self.fc21(fc1)
        r2 = self.fc22(fc1)
        return r1, r2

    def reparameterize(self, mu, logvar):
        if self.training:
            std = logvar.mul(0.5).exp()
            eps = torch.randn_like(std)
            return eps.mul(std).add_(mu)
        else:
            return mu

    def decode(self, z):
        # Apply GRU
        gru_out, _ = self.gru(z.unsqueeze(1))  # Add sequence dimension
        gru_out = self.dropout(gru_out)

        # Apply Attention
        attn_output, _ = self.attention(gru_out, gru_out, gru_out)
        attn_output = attn_output.mean(dim=1)  # Aggregate over sequence dimension

        fc3 = self.relu(self.fc_bn4(self.fc4(attn_output)))
        lin4 = self.relu(self.lin_bn4(self.linear4(fc3)))
        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))
        return self.softmax(self.lin_bn6(self.linear6(lin5)))  # Apply Softmax

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar


class customLoss(nn.Module):
    def __init__(self):
        super(customLoss, self).__init__()
        self.mse_loss = nn.MSELoss(reduction="sum")

    def forward(self, x_recon, x, mu, logvar):
        loss_MSE = self.mse_loss(x_recon, x)
        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
        return loss_MSE + loss_KLD


def train_and_evaluate(model, train_loader, val_loader, learning_rate=0.001, num_epochs=100):
    criterion = customLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    train_losses, val_losses = [], []

    all_val_labels = []
    all_val_preds = []

    for epoch in range(num_epochs):
        model.train()
        epoch_train_loss = 0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs, mu, logvar = model(inputs)
            labels = torch.argmax(labels, dim=1)
            loss = criterion(outputs, inputs, mu, logvar)
            loss.backward()
            optimizer.step()
            epoch_train_loss += loss.item()
        train_losses.append(epoch_train_loss / len(train_loader))

        model.eval()
        epoch_val_loss = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                outputs, mu, logvar = model(inputs)
                loss = criterion(outputs, inputs, mu, logvar)
                epoch_val_loss += loss.item()

                # Collect validation labels and predictions
                features, _ = model.encode(inputs)
                all_val_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())
                # Use encoded features to predict
                all_val_preds.extend(features.cpu().numpy())

        val_losses.append(epoch_val_loss / len(val_loader))

    # Train a simple classifier on the encoded features
    clf = LogisticRegression(max_iter=1000)
    encoded_train_features = np.array(all_val_preds)
    encoded_train_labels = np.array(all_val_labels)
    clf.fit(encoded_train_features, encoded_train_labels)

    return train_losses, val_losses, clf, all_val_labels


my_model = Autoencoder(D_in=X_train_tensor.shape[1], H=50, H2=12, latent_dim=num_classes, hidden_dim=64, num_layers=2)
train_losses, val_losses, clf, all_val_labels = train_and_evaluate(my_model, train_loader, val_loader,
                                                                   learning_rate=0.001, num_epochs=100)

plt.figure(figsize=(12, 6))
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.title('Model')
plt.legend()
plt.tight_layout()
plt.show()

# Print metrics
encoded_val_labels = np.array(all_val_labels)
encoded_val_features = np.array(all_val_preds)
val_predictions = clf.predict(encoded_val_features)
accuracy = accuracy_score(encoded_val_labels, val_predictions)
class_report = classification_report(encoded_val_labels, val_predictions)
f1 = f1_score(encoded_val_labels, val_predictions, average='weighted')

print(f'Accuracy: {accuracy:.4f}')
print(f'F1 Score: {f1:.4f}')
print(class_report)

# Get output for test set
# ----------------------------------------------------------------------------------------------------------------------
my_model.eval()
with torch.no_grad():
    test_features, _ = my_model.encode(X_test_tensor)
    test_features = test_features.cpu().numpy()

# Predict on test features
test_preds = clf.predict(test_features)

# Create DataFrame for results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': test_preds
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)

"""###CatBoost"""

import pandas as pd
import numpy as np
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

# Paths to data files
train_path = 'train.csv'
test_path = 'test.csv'

# Load data
df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

# Define features and labels
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Split the data into training and validation sets
X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(
    X_train_scaled, y_train, test_size=0.2, random_state=42
)

# Define parameter ranges
depths = [7, 8]
iterations_list = [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]

best_accuracy = 0
best_params = {}

for depth in depths:
    for iterations in iterations_list:
        print(f"Training with depth={depth} and iterations={iterations}")

        model = CatBoostClassifier(
            iterations=iterations,
            depth=depth,
            learning_rate=0.1,
            loss_function='MultiClass',
            cat_features=[]
        )

        model.fit(X_train_scaled, y_train, verbose=0)

        y_val_pred = model.predict(X_val_scaled)
        accuracy = accuracy_score(y_val, y_val_pred)

        print(f'Validation Accuracy: {accuracy:.4f}')

        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_params = {
                'iterations': iterations,
                'depth': depth
            }

print(f"Best Accuracy: {best_accuracy:.4f}")
print(f"Best Parameters: {best_params}")

# Train the final model with the best parameters
best_model = CatBoostClassifier(
    iterations=best_params['iterations'],
    depth=best_params['depth'],
    learning_rate=0.1,
    loss_function='MultiClass',
    cat_features=[]
)

best_model.fit(X_train_scaled, y_train, verbose=0)

# Predict on the test set
y_test_pred = best_model.predict(X_test_scaled)
y_test_pred = y_test_pred.ravel()

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_pred
})

results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###Customized Model"""

if __name__ == '__main__':  # prevent local errors
    # import packages
    import numpy as np
    import pandas as pd
    import torch
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import accuracy_score, classification_report, f1_score
    from sklearn.utils import resample
    from sklearn.ensemble import AdaBoostClassifier
    from sklearn.tree import DecisionTreeClassifier
    from torch.utils.data import DataLoader, TensorDataset
    import torch.nn as nn
    import torch.optim as optim
    import torch.nn.functional as F
    import matplotlib.pyplot as plt

    # data pre-processing
    # ----------------------------------------------------------------------------------------------------------------------
    train_path = 'train.csv'
    test_path = 'test.csv'

    df_train = pd.read_csv(train_path)
    df_test = pd.read_csv(test_path)

    # Print some rows to understand the structure
    print(df_train.head())
    print(df_test.head())

    # Preprocessing
    scaler = StandardScaler()
    X_train = df_train.drop(columns=['ID', 'Label'])
    y_train = df_train['Label']
    X_test = df_test.drop(columns=['ID'])

    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Splitting data for training and validation
    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)
    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)

    # print("Unique values in labels:", torch.unique(y_train_tensor)) # [0, 1, 2]

    X_train, X_val, y_train, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.2, random_state=42)

    # one-hot
    num_classes = len(torch.unique(y_train_tensor))
    y_train_one_hot = F.one_hot(y_train, num_classes=num_classes).float()
    y_val_one_hot = F.one_hot(y_val, num_classes=num_classes).float()

    train_dataset = TensorDataset(X_train, y_train_one_hot)
    val_dataset = TensorDataset(X_val, y_val_one_hot)

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0, drop_last=True)

    # Create Models
    # ----------------------------------------------------------------------------------------------------------------------
    class Encoder(nn.Module):
        def __init__(self, input_size, hidden_size, num_layers=1):
            super(Encoder, self).__init__()
            self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=0.7)
            self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True,
                              bidirectional=True, dropout=0.7)
            self.dropout = nn.Dropout(p=0.7)

        def forward(self, x):
            lstm_out, (hn, cn) = self.rnn(x)
            lstm_out = self.dropout(lstm_out)

            gru_out, _ = self.gru(x)
            gru_out = self.dropout(gru_out)

            combined_out = torch.cat((lstm_out, gru_out), dim=-1)
            return combined_out, (hn, cn)


    class Decoder(nn.Module):
        def __init__(self, hidden_size, output_size, num_layers=1):
            super(Decoder, self).__init__()
            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=0.7)
            self.fc = nn.Linear(hidden_size, output_size)
            self.dropout = nn.Dropout(p=0.7)

        def forward(self, x, hidden):
            output, hidden = self.rnn(x, hidden)
            output = self.dropout(output)
            output = self.fc(output)
            return output, hidden


    class EncoderDecoderWithAttention(nn.Module):
        def __init__(self, input_size, hidden_size, output_size, num_layers=1):
            super(EncoderDecoderWithAttention, self).__init__()
            self.encoder = Encoder(input_size, hidden_size, num_layers)
            self.attention = nn.MultiheadAttention(embed_dim=hidden_size*4, num_heads=4, batch_first=True)
            self.decoder = Decoder(hidden_size*4, hidden_size * 2, num_layers)

            self.fc1 = nn.Linear(hidden_size * 2, 128)
            self.fc2 = nn.Linear(128, 64)
            self.fc3 = nn.Linear(64, output_size)

            self.dropout = nn.Dropout(p=0.7)
            self.softmax = nn.Softmax(dim=-1)

        def forward(self, x):
            encoder_out, (hn, cn) = self.encoder(x)
            attention_out, _ = self.attention(encoder_out, encoder_out, encoder_out)
            decoder_out, _ = self.decoder(attention_out, (hn[:2], cn))

            out = self.fc1(decoder_out)
            out = torch.relu(out)
            out = self.fc2(out)
            out = torch.relu(out)
            out = self.fc3(out)
            out = self.softmax(out)
            return out


    """
    # Bagging
    class BaggingClassifier:
        def __init__(self, model_class, n_estimators=5, **model_kwargs):
            self.model_class = model_class
            self.n_estimators = n_estimators
            self.model_kwargs = model_kwargs
            self.models = []
            self.train_losses_per_model = []

        def fit(self, X_train, y_train, num_epochs=100, batch_size=64, learning_rate=0.001):
            for _ in range(self.n_estimators):
                # Create a bootstrap sample
                X_resampled, y_resampled = resample(X_train, y_train)
                train_dataset = TensorDataset(torch.tensor(X_resampled, dtype=torch.float32),
                                              torch.tensor(y_resampled, dtype=torch.long))
                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)

                # Initialize and train the model
                model = self.model_class(**self.model_kwargs)
                train_losses = self._train_model(model, train_loader, num_epochs, learning_rate)
                self.models.append(model)
                self.train_losses_per_model.append(train_losses)

        def _train_model(self, model, train_loader, num_epochs, learning_rate):
            criterion = nn.CrossEntropyLoss()
            optimizer = optim.Adam(model.parameters(), lr=learning_rate)

            train_losses = []

            for epoch in range(num_epochs):
                model.train()
                epoch_loss = 0

                for inputs, labels in train_loader:
                    optimizer.zero_grad()
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()
                    epoch_loss += loss.item()

                train_losses.append(epoch_loss / len(train_loader))

            return train_losses

        def predict(self, X):
            all_preds = np.zeros((X.shape[0], len(np.unique(y_train_tensor))))
            for model in self.models:
                model.eval()
                with torch.no_grad():
                    outputs = model(torch.tensor(X, dtype=torch.float32))
                    preds = torch.argmax(outputs, dim=1).numpy()
                    all_preds += np.eye(len(np.unique(y_train_tensor)))[preds]

            final_preds = np.argmax(all_preds, axis=1)
            return final_preds
    """
    # Training
    # ----------------------------------------------------------------------------------------------------------------------
    def train_and_evaluate(model, train_loader, val_loader, learning_rate=0.001, num_epochs=100):

        criterion = nn.CrossEntropyLoss()  # cross-entropy loss
        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)

        train_losses, val_losses = [], []

        for epoch in range(num_epochs):
            model.train()
            epoch_train_loss = 0

            for inputs, labels in train_loader:
                optimizer.zero_grad()
                outputs = model(inputs)

                labels = torch.argmax(labels, dim=1)
                loss = criterion(outputs, labels)

                loss.backward()
                optimizer.step()
                epoch_train_loss += loss.item()

            train_losses.append(epoch_train_loss / len(train_loader))

            model.eval()
            epoch_val_loss = 0
            all_labels, all_preds = [], []
            with torch.no_grad():
                for inputs, labels in val_loader:
                    outputs = model(inputs)
                    labels = torch.argmax(labels, dim=1)
                    loss = criterion(outputs, labels)
                    epoch_val_loss += loss.item()

                    _, preds = torch.max(outputs, 1)
                    all_labels.extend(labels.cpu().numpy())
                    all_preds.extend(preds.cpu().numpy())

            val_losses.append(epoch_val_loss / len(val_loader))
            accuracy = accuracy_score(all_labels, all_preds)
            class_report = classification_report(all_labels, all_preds)
            f1 = f1_score(all_labels, all_preds, average='weighted')

            # print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')

        return train_losses, val_losses, accuracy, class_report, f1

    """
    # Eval with Bagging
    bagging_model = BaggingClassifier(model_class=SimpleNN, n_estimators=5)
    bagging_model.fit(X_train_tensor.numpy(), y_train_tensor.numpy(), num_epochs=100, batch_size=64,
                      learning_rate=0.001)
    y_val_preds = bagging_model.predict(X_val.numpy())
    y_test_preds = bagging_model.predict(X_test_tensor.numpy())

    # Compute metrics
    accuracy = accuracy_score(y_val.numpy(), y_val_preds)
    class_report = classification_report(y_val.numpy(), y_val_preds)
    f1 = f1_score(y_val.numpy(), y_val_preds, average='weighted')

    # Plots
    # ----------------------------------------------------------------------------------------------------------------------
    print(f'Validation Accuracy: {accuracy:.4f}')
    print(f'Validation F1 Score: {f1:.4f}')
    print(class_report)

    # Save test predictions
    results_df = pd.DataFrame({
        'ID': df_test['ID'],
        'Label': y_test_preds
    })
    results_df.to_csv('submission.csv', index=False)
    print('submission.csv')

    # Plot train vs validation loss
    plt.figure(figsize=(12, 6))
    for i, losses in enumerate(bagging_model.train_losses_per_model):
        plt.plot(losses, label=f'Model {i + 1} Train Loss')
    plt.title('Model Loss')
    plt.legend()
    plt.tight_layout()
    plt.show()
    """

    # Without bagging
    my_model = EncoderDecoderWithAttention(input_size=X_train_tensor.shape[1], hidden_size=32, output_size=num_classes, num_layers=2)

    train_losses, val_losses, accuracy, class_report, f1 = train_and_evaluate(my_model, train_loader, val_loader,
                                                                              learning_rate=0.001, num_epochs=100)

    # Plots
    # ----------------------------------------------------------------------------------------------------------------------
    plt.figure(figsize=(12, 6))

    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.title('Model')
    plt.legend()

    plt.tight_layout()
    plt.show()

    # Print metrics
    print(f'Accuracy: {accuracy:.4f}')
    print(f'F1 Score: {f1:.4f}')
    print(class_report)

    # get output
    # ----------------------------------------------------------------------------------------------------------------------
    my_model.eval()
    with torch.no_grad():
        test_predictions = my_model(X_test_tensor)
        _, predicted_labels = torch.max(test_predictions, 1)

    # Create DataFrame for results
    results_df = pd.DataFrame({
        'ID': df_test['ID'],
        'Label': predicted_labels.cpu().numpy()
    })

    # Save results to CSV
    results_df.to_csv('submission.csv', index=False)
    print('submission.csv')

"""###ExtremeLM"""

import pandas as pd
import numpy as np
from hpelm import ELM
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder

train_path = 'train.csv'
test_path = 'test.csv'

# Load data
df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

# Define features and labels
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

# One-Hot Encode the labels
encoder = OneHotEncoder(sparse_output=False)
y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))  # Ensure y_train is a 2D array

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)  # Scale test data

# Split the data into training and validation sets
X_train_scaled, X_val_scaled, y_train_encoded, y_val_encoded = train_test_split(
    X_train_scaled, y_train_encoded, test_size=0.2, random_state=42
)

# Initialize the ELM model
model = ELM(X_train_scaled.shape[1], y_train_encoded.shape[1])  # Output size should match number of classes
model.add_neurons(1000, "tanh")
model.train(X_train_scaled, y_train_encoded, "c", output_act='softmax')

# Predict on the test set
y_pred = model.predict(X_test_scaled)  # Use the scaled test data

# Convert the predictions from one-hot encoding back to class labels
y_pred_labels = encoder.inverse_transform(y_pred)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_pred_labels.flatten()  # Flatten to ensure it's a 1D array
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###Imbalanced"""

from imbens.ensemble import SelfPacedEnsembleClassifier
import pandas as pd
import numpy as np
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

# Paths to data files
train_path = 'train.csv'
test_path = 'test.csv'

# Load data
df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

# Define features and labels
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Split the data into training and validation sets
X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(
    X_train_scaled, y_train, test_size=0.2, random_state=42
)

clf = SelfPacedEnsembleClassifier(random_state=42)
clf.fit(X_train_scaled, y_train)

y_pred = clf.predict(X_test_scaled)

results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_pred
})

results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""#LGBM"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score

# Paths to data files
train_path = 'train.csv'
test_path = 'test.csv'

# Load data
df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

# Define features and labels
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Split the data into training and validation sets
X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(
    X_train_scaled, y_train, test_size=0.2, random_state=42
)

# Initialize the LightGBM model
lgbm_model = LGBMClassifier(random_state=42, objective='multiclass', num_class=len(np.unique(y_train)))

# Define the parameter grid
param_grid = {
    'n_estimators': [80, 100, 120],
    'num_leaves': [4, 6, 8],
    'max_depth': [2, 3, 4]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(
    estimator=lgbm_model,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,  # Number of cross-validation folds
    verbose=1,
    n_jobs=-1  # Use all available CPUs
)

# Fit GridSearchCV
grid_search.fit(X_train_scaled, y_train)

# Print best parameters and best score
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

# Get the best model
best_lgbm_model = grid_search.best_estimator_

# Predict on validation set
y_val_pred = best_lgbm_model.predict(X_val_scaled)
accuracy = accuracy_score(y_val, y_val_pred)
print(f'Validation Accuracy: {accuracy:.4f}')

# Predict on test set
y_test_pred = best_lgbm_model.predict(X_test_scaled)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_pred
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###8.1"""

if __name__ == '__main__':  # prevent local errors
    # import packages
    import numpy as np
    import pandas as pd
    import torch
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import accuracy_score, classification_report, f1_score
    from torch.utils.data import DataLoader, TensorDataset
    import torch.nn as nn
    import torch.optim as optim
    import matplotlib.pyplot as plt

    # data pre-processing
    # ----------------------------------------------------------------------------------------------------------------------
    train_path = 'train.csv'
    test_path = 'test.csv'

    df_train = pd.read_csv(train_path)
    df_test = pd.read_csv(test_path)

    # Print some rows to understand the structure
    print(df_train.head())
    print(df_test.head())

    # Preprocessing
    scaler = StandardScaler()
    X_train = df_train.drop(columns=['ID', 'Label'])
    y_train = df_train['Label']
    X_test = df_test.drop(columns=['ID'])

    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Splitting data for training and validation
    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)
    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)

    X_train, X_val, y_train, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.2, random_state=42)

    train_dataset = TensorDataset(X_train, y_train)
    val_dataset = TensorDataset(X_val, y_val)

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0, drop_last=True)


    # Create Models
    # ----------------------------------------------------------------------------------------------------------------------
    class SimpleNN(nn.Module):
        def __init__(self, hidden_layers, nodes_per_layer):
            super(SimpleNN, self).__init__()
            layers = []
            input_size = X_train_tensor.shape[1]

            for _ in range(hidden_layers):
                layers.append(nn.Linear(input_size, nodes_per_layer))
                layers.append(nn.ReLU())
                input_size = nodes_per_layer

            layers.append(nn.Linear(input_size, len(np.unique(y_train_tensor))))
            layers.append(nn.Softmax(dim=1))

            self.model = nn.Sequential(*layers)

        def forward(self, x):
            return self.model(x)

    # Training
    # ----------------------------------------------------------------------------------------------------------------------
    def train_and_evaluate(model, train_loader, val_loader, learning_rate=0.001, num_epochs=100):
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)

        train_losses, val_losses = [], []

        for epoch in range(num_epochs):
            model.train()
            epoch_train_loss = 0
            for inputs, labels in train_loader:
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                epoch_train_loss += loss.item()

            train_losses.append(epoch_train_loss / len(train_loader))

            model.eval()
            epoch_val_loss = 0
            all_labels, all_preds = [], []
            with torch.no_grad():
                for inputs, labels in val_loader:
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    epoch_val_loss += loss.item()

                    _, preds = torch.max(outputs, 1)
                    all_labels.extend(labels.cpu().numpy())
                    all_preds.extend(preds.cpu().numpy())

            val_losses.append(epoch_val_loss / len(val_loader))
            accuracy = accuracy_score(all_labels, all_preds)
            class_report = classification_report(all_labels, all_preds)
            f1 = f1_score(all_labels, all_preds, average='weighted')

            # print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')

        return train_losses, val_losses, accuracy, class_report, f1


    # Model configurations
    model1 = SimpleNN(hidden_layers=1, nodes_per_layer=64)
    model2 = SimpleNN(hidden_layers=2, nodes_per_layer=32)
    model3 = SimpleNN(hidden_layers=2, nodes_per_layer=64)

    train_losses1, val_losses1, accuracy1, class_report1, f1_1 = train_and_evaluate(model1, train_loader, val_loader,
                                                                                    learning_rate=0.001, num_epochs=100)
    train_losses2, val_losses2, accuracy2, class_report2, f1_2 = train_and_evaluate(model2, train_loader, val_loader,
                                                                                    learning_rate=0.001, num_epochs=100)
    train_losses3, val_losses3, accuracy3, class_report3, f1_3 = train_and_evaluate(model3, train_loader, val_loader,
                                                                                    learning_rate=0.001, num_epochs=100)

    # Plots
    # ----------------------------------------------------------------------------------------------------------------------
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 3, 1)
    plt.plot(train_losses1, label='Train Loss')
    plt.plot(val_losses1, label='Val Loss')
    plt.title('Model 1 Hidden Layer, 64 Nodes')
    plt.legend()

    plt.subplot(1, 3, 2)
    plt.plot(train_losses2, label='Train Loss')
    plt.plot(val_losses2, label='Val Loss')
    plt.title('Model 2 Hidden Layers, 32 Nodes Each')
    plt.legend()

    plt.subplot(1, 3, 3)
    plt.plot(train_losses3, label='Train Loss')
    plt.plot(val_losses3, label='Val Loss')
    plt.title('Model 2 Hidden Layers, 64 Nodes Each')
    plt.legend()

    plt.tight_layout()
    plt.show()

    # Print metrics
    print(f'Model 1 Accuracy: {accuracy1:.4f}')
    print(f'Model 1 F1 Score: {f1_1:.4f}')
    print(class_report1)

    print(f'Model 2 Accuracy: {accuracy2:.4f}')
    print(f'Model 2 F1 Score: {f1_2:.4f}')
    print(class_report2)

    print(f'Model 3 Accuracy: {accuracy3:.4f}')
    print(f'Model 3 F1 Score: {f1_3:.4f}')
    print(class_report3)

    # ----------------------------------------------------------------------------------------------------------------------

"""###SVM"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

train_path = 'train.csv'
test_path = 'test.csv'

# Load data
df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

# Define features and labels
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

# Encode the labels
encoder = OneHotEncoder(sparse_output=False)
y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))
y_train_np = np.argmax(y_train_encoded, axis=1)  # Convert one-hot encoded labels back to integer labels

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Split the data into training and validation sets
X_train_scaled, X_val_scaled, y_train_np, y_val_np = train_test_split(
    X_train_scaled, y_train_np, test_size=0.2, random_state=42
)

# Reduced parameter grid for GridSearchCV
param_grid = {
    'C': [0.1, 1],
    'gamma': ['scale','auto', 0.01],
    'kernel': ['rbf', 'linear']
}

# Initialize the SVC model
svc = SVC()

# Initialize GridSearchCV
grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)

# Train the model with GridSearchCV
grid_search.fit(X_train_scaled, y_train_np)

# Print the best parameters and best score
print(f'Best parameters found: {grid_search.best_params_}')
print(f'Best accuracy found: {grid_search.best_score_:.4f}')

# Predict on the validation set with the best model
best_model = grid_search.best_estimator_
y_val_pred = best_model.predict(X_val_scaled)
accuracy = accuracy_score(y_val_np, y_val_pred)
print(f'Validation Accuracy: {accuracy:.4f}')

# Predict on the test set with the best model
y_test_pred = best_model.predict(X_test_scaled)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_pred
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###TabNet"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score


train_path = 'train.csv'
test_path = 'test.csv'

df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

scaler = StandardScaler()
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

X_train_np = X_train.values
y_train_np = y_train.values
X_test_np = X_test.values

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled, X_val_scaled, y_train_np, y_val_np = train_test_split(
    X_train_scaled, y_train_np, test_size=0.2, random_state=42
)

tabnet_model = TabNetClassifier(
    n_d=4,  # Adjust based on experimentation
    n_a=4,  # Adjust based on experimentation
    n_steps=4,  # Adjust based on experimentation
    gamma=1.5,  # Adjust based on experimentation
    n_independent=4,  # Adjust based on experimentation
    n_shared=2,  # Adjust based on experimentation
    seed=42
)

# Train the model
tabnet_model.fit(
    X_train=X_train_scaled,
    y_train=y_train_np,
    eval_set=[(X_val_scaled, y_val_np)],
    eval_name=['val'],
    eval_metric=['accuracy'],
    batch_size=32,
    virtual_batch_size=32,
    num_workers=0,
    drop_last=False,
    max_epochs=100
)

# Predict on validation set
y_val_pred = tabnet_model.predict(X_val_scaled)
accuracy = accuracy_score(y_val_np, y_val_pred)
print(f'Validation Accuracy: {accuracy:.4f}')

# Predict on test set
y_test_pred = tabnet_model.predict(X_test_scaled)

# Prepare results
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_pred
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###Best So far"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models, Input, Model, Sequential
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Load data
train_path = 'train.csv'
test_path = 'test.csv'

df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

# Preprocessing
scaler = StandardScaler()
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

X_train_np = X_train.values
y_train_np = y_train.values
X_test_np = X_test.values

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled, X_val_scaled, y_train_np, y_val_np = train_test_split(
    X_train_scaled, y_train_np, test_size=0.2, random_state=42
)

# One-hot encode the labels
num_classes = len(np.unique(y_train_np))
y_train_one_hot = to_categorical(y_train_np, num_classes=num_classes)
y_val_one_hot = to_categorical(y_val_np, num_classes=num_classes)

# Convert numpy arrays to TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train_one_hot))
val_dataset = tf.data.Dataset.from_tensor_slices((X_val_scaled, y_val_one_hot))
test_dataset = tf.data.Dataset.from_tensor_slices(X_test_scaled)

# Shuffle, batch, and prefetch the training dataset
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.AUTOTUNE)
val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)

LATENT_SIZE = 32
input_size = X_train_scaled.shape[1]

# Define the Encoder
encoder = Sequential([
    Input(shape=(input_size,)),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(LATENT_SIZE, activation='relu')
])

# Define the Decoder
decoder = Sequential([
    Input(shape=(LATENT_SIZE,)),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(input_size, activation='softmax')  # Adjust output layer
])

# Build the Autoencoder
autoencoder_input = Input(shape=(input_size,))
encoded_img = encoder(autoencoder_input)
decoded_img = decoder(encoded_img)
autoencoder = Model(autoencoder_input, decoded_img)
autoencoder.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

autoencoder.summary()
autoencoder.fit(train_dataset, epochs=100, validation_data=val_dataset)

test_predictions = autoencoder.predict(X_test_scaled)

# Create results DataFrame
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': np.argmax(test_predictions, axis=1)
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###Dense Only"""

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import plot_model
from sklearn.preprocessing import StandardScaler, LabelEncoder

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau

def build_improved_model(input_dim, num_classes, learning_rate=0.001):
    model = Sequential()
    model.add(Dense(1024, input_dim=input_dim, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(Dropout(0.7))

    model.add(Dense(512, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(Dropout(0.7))

    model.add(Dense(256, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(Dropout(0.7))

    model.add(Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(Dropout(0.7))

    model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(Dropout(0.7))

    model.add(Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(Dropout(0.7))

    model.add(Dense(num_classes, activation='softmax'))

    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer,
                  loss=CategoricalCrossentropy(),
                  metrics=['accuracy'])
    return model


# Custom callback to stop training when accuracy reaches 0.65
class EarlyStoppingByAccuracy(Callback):
    def __init__(self, monitor='val_accuracy', value=0.65, verbose=1):
        super(Callback, self).__init__()
        self.monitor = monitor
        self.value = value
        self.verbose = verbose

    def on_epoch_end(self, epoch, logs=None):
        current = logs.get(self.monitor)
        if current is not None and current >= self.value:
            self.model.stop_training = True
            if self.verbose > 0:
                print(f"\nEpoch {epoch+1}: Early stopping threshold reached. {self.monitor} = {current}")

# One-hot encode the target labels
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse_output=False)
y_train_one_hot = encoder.fit_transform(y_train_np.reshape(-1, 1))
y_val_one_hot = encoder.transform(y_val_np.reshape(-1, 1))

# Build and train the model
num_classes = y_train_one_hot.shape[1]  # Number of classes from one-hot encoded labels
model = build_improved_model(input_dim=X_train_scaled.shape[1], num_classes=num_classes, learning_rate=0.001)

# EarlyStopping, ReduceLROnPlateau, and ModelCheckpoint
early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.00001)
model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy')

# Learning rate warmup
class WarmUpLearningRateScheduler(Callback):
    def __init__(self, warmup_epochs, initial_lr, verbose=0):
        super(WarmUpLearningRateScheduler, self).__init__()
        self.warmup_epochs = warmup_epochs
        self.initial_lr = initial_lr
        self.verbose = verbose

    def on_epoch_begin(self, epoch, logs=None):
        if epoch < self.warmup_epochs:
            lr = self.initial_lr * (epoch + 1) / self.warmup_epochs
            tf.keras.backend.set_value(self.model.optimizer.lr, lr)
            if self.verbose > 0:
                print(f'\nEpoch {epoch+1}: WarmUpLearningRateScheduler setting learning rate to {lr}.')

warmup_lr = WarmUpLearningRateScheduler(warmup_epochs=10, initial_lr=0.001)  # Increased warm-up epochs
early_stopping_by_accuracy = EarlyStoppingByAccuracy(monitor='val_accuracy', value=0.64)

history = model.fit(X_train_scaled, y_train_one_hot,
                    epochs=100,
                    validation_data=(X_val_scaled, y_val_one_hot),
                    batch_size=64,
                    verbose=2,
                    callbacks=[early_stopping, reduce_lr, model_checkpoint, warmup_lr, early_stopping_by_accuracy])

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot training and validation accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

y_test_pred_prob = model.predict(X_test_scaled)

# Convert probabilities to class labels
y_test_pred_labels = np.argmax(y_test_pred_prob, axis=1)

# Prepare results DataFrame
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_pred_labels
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

"""###ECG"""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, GlobalAveragePooling1D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras import regularizers

# Load and preprocess data (assuming df_train and df_test are already defined)
scaler = StandardScaler()
X_train = df_train.drop(columns=['ID', 'Label'])
y_train = df_train['Label']
X_test = df_test.drop(columns=['ID'])

X_train_np = X_train.values
y_train_np = y_train.values
X_test_np = X_test.values


X_train_scaled = X_train_np.reshape(-1, 300, 100)
X_test_scaled = X_test_np.reshape(-1, 300, 100)

# Splitting the dataset
X_train_scaled, X_val_scaled, y_train_np, y_val_np = train_test_split(
    X_train_scaled, y_train_np, test_size=0.2, random_state=42
)

# One-hot encode the labels
num_classes = len(np.unique(y_train_np))
y_train_one_hot = to_categorical(y_train_np, num_classes=num_classes)
y_val_one_hot = to_categorical(y_val_np, num_classes=num_classes)

# Convert numpy arrays to TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train_one_hot))
val_dataset = tf.data.Dataset.from_tensor_slices((X_val_scaled, y_val_one_hot))

# Shuffle, batch, and prefetch the training dataset
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.AUTOTUNE)
val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)

LATENT_SIZE = 32
input_size = X_train_scaled.shape[1]

def network(X_train, y_train, X_val, y_val):
    # Define the input shape
    im_shape = (300, 100)

    # Input layer
    inputs = Input(shape=im_shape)

    x = Conv1D(128, kernel_size=3, activation='relu')(inputs)
    x = MaxPooling1D(pool_size=2)(x)
    x = Conv1D(64, kernel_size=3, activation='relu')(x)
    x = GlobalAveragePooling1D()(x)
    x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)
    x = Dropout(0.5)(x)
    outputs = Dense(num_classes, activation='softmax')(x)

    # Compile the model
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # Learning rate scheduler function
    def scheduler(epoch, lr):
      return float(lr * tf.math.exp(-0.1)) if epoch > 10 else float(lr)


    # Callbacks
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=8),
        ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True),
        LearningRateScheduler(scheduler)
    ]

    # Train the model
    history = model.fit(
        X_train, y_train,
        epochs=100,
        callbacks=callbacks,
        batch_size=32,
        validation_data=(X_val, y_val)
    )

    # Load best model weights
    model.load_weights('best_model.keras')

    return model, history

# Train the model
model, history = network(X_train_scaled, y_train_one_hot, X_val_scaled, y_val_one_hot)

# Predict on the test set
X_test_reshaped = X_test_scaled
y_test_pred_prob = model.predict(X_test_reshaped)

# Convert probabilities to class labels
y_test_pred_labels = np.argmax(y_test_pred_prob, axis=1)

# Prepare results DataFrame
results_df = pd.DataFrame({
    'ID': df_test['ID'],
    'Label': y_test_pred_labels
})

# Save results to CSV
results_df.to_csv('submission.csv', index=False)
print('submission.csv')

def plot_training_history(history):
    # Extract loss and accuracy from the history object
    history_dict = history.history
    epochs = range(1, len(history_dict['loss']) + 1)

    # Plot training and validation loss
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, history_dict['loss'], 'b', label='Training loss')
    plt.plot(epochs, history_dict['val_loss'], 'r', label='Validation loss')
    plt.title('Training and validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot training and validation accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, history_dict['accuracy'], 'b', label='Training accuracy')
    plt.plot(epochs, history_dict['val_accuracy'], 'r', label='Validation accuracy')
    plt.title('Training and validation accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Assuming `history` is returned from the `network` function
plot_training_history(history)